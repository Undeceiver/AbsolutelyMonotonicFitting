\documentclass[12pt,a4paper]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{hyperref}

\input{include.tex}
\input{\pathcommon{standard_theorems}}
\input{\pathcommon{derivatives}}
\input {\pathcommon{common_macros}}

\newcommand{\realfunction}[2] {{#1: #2 \rightarrow \mathbb{R}}}
\newcommand{\uexp}[1] {{\text{uexp}_{#1}}}

\title{Fitting absolutely monotonic real analytic functions in bounded intervals}
\author{Juan Casanova}

\begin{document}

\maketitle

This is the abstract.

\tableofcontents

\section{Introduction}

\subsection{Absolutely monotonic functions}

A real function is {\emph{absolutely monotonic}} if all of its derivatives are non-negative. Absolutely monotonic functions grow faster and faster as we approach higher values, curving upwards in every sense. They are growing and convex, though not all growing convex functions are absolutely monotonic.

Convex smooth functions, and in particular fitting convex smooth functions from samples, have been studied extensively \cite{2001_groeneboom_estimation_convex_function, 2015_lu_spline_monotonic_regression, 2015_lebair_derivative_constrain_spline, 2008_aguilera_approximating_optimization_convex_functions, 2013_hannah_multivariate_convex_regression, 2002_holmstr_parameter_estimation_fitting_exponentials, 2005_lachand_minimizing_convex_bodies, 2011_kopotun_shape_preserving_approximation_algebraic_polynomials} due to the multitude of applications in economics, statistics, machine learning, etc. Like other types of {\emph{shape-constrained estimation}}, we know or wish the resulting function to fulfill certain growth or smoothness properties, but also wish to fit the available data as best as possible.\\

\subsection{Motivating problem: reward curves}

The motivating problem for this paper is the production of {\emph{reward curves from scores in a competitive single player game}}. Specifically, Beat Saber\footnote{\url{https://beatsaber.com/}} is a virtual reality rhythm game released in 2018 in which players play single player maps with a maximum possible score, attempting to get as close as possible. Scores in Beat Saber are often represented as percentages of the maximum possible score. Beat Saber has rich scoring mechanics\footnote{\url{https://bsmg.wiki/ranking-guide.html}}, and a healthy competitive scene with upwards of 60,000 active ranked players\footnote{Verified using BeatLeader's search functionality at \url{https://beatleader.com/ranking/1?mapsType=all&recentScoreTime=1721433600}}, which can be observed through its two most popular ranked leaderboards: ScoreSaber\footnote{\url{https://scoresaber.com/}} and BeatLeader\footnote{\url{https://beatleader.xyz/}}. Competitive Beat Saber focuses on large pools of {\emph{custom}} maps made by members of the community ({\emph{mappers}}) that undergo a ranking process\footnote{\url{https://beatleader.wiki/en/ranking/Ranking-your-map}} to ensure their competitive viability. For example, BeatLeader offers over 3500 different ranked maps\footnote{\url{https://beatleader.xyz/leaderboards}}.

Experienced Beat Saber players observe a high diminishing returns difficulty curve. The closer to 100\%, the harder it is to improve the score further. There are exactly two 100\% scores across all ranked maps in Beat Leader (over 3500 maps, over 60,000 players), on particularly easy maps by particularly skilled players. The difference in difficulty between a 98\% and a 99\% score in a map is orders of magnitude larger than the difference between a 90\% and a 91\%. Most scores that do not fail the map are over 70\% to begin with.

Different maps do not just have different difficulties, but also different difficulty {\emph{curves}}, with the difficulty accumulating at different relative ranges of the score spectrum, while always preserving the diminishing returns nature. The problem of finding adequate reward curves for each map is difficult and highly sought-after by the Beat Saber ranked community. Shape-constrained fitting from player scores is a valuable tool in this context. Naturally, a higher score should always give a higher reward (often quantified as Performance Points (PP)), introducing a growing constraint on the reward curve. Moreover, the diminishing returns nature justifies introducing further growth constraints that increase the rate at which the rewards increase. While convexity constraints could be used, there are growing convex curves that do not adequately reflect the ever increasingly difficult nature of approaching 100\% score in Beat Saber maps (see, for example, figure \ref{convex_not_am}). Therefore, we instead consider the more constraining problem of fitting smooth absolutely monotonic curves from sample scores.\\

\begin{figure}
\caption{\label{convex_not_am}Smooth piecewise polynomial that is growing and convex but not absolutely monotonic}
\centering
\includegraphics[width=0.75\textwidth]{convex_not_am.png}
\end{figure}

\subsection{Problem statement}

As discussed, we consider the problem of, given a random {\bf{sample}} of an unknown single variable {\bf{real valued}} function in a {\bf{bounded interval}}, finding {\bf{absolutely monotonic}} functions that best approximate the data. We will, however, compare with some methods that only guarantee convex functions due to their prominence and to understand the relative advantages and disadvantages of them.

We presume noise in the data. In the Beat Saber map context, the x axis indicates the score obtained in the map by the player, and the y axis indicates the reward associated with it, which in the data is represented by the quantified player skill of the player that produced the score. The player skill of a player in a ranked setting represents {\emph{their best possible performance}}, meaning that better players can sometimes produce worse scores (if not taking the map seriously, being unlucky, or having less than ideal circumstances), but it is far more unlikely that a player will produce a score above their skill level. Therefore, we presume noise in the data will have a strong positive bias. In other words, our estimation should ideally {\bf{lowball}} the data. In order to achieve this, we use asymmetric loss functions in our methods. We consider two different asymmetric loss functions: 

\begin{enumerate}
\item Pinball loss
\begin{equation}
\begin{array}{lll}
l_1(r) =& \tau r &\text{if } r \geq 0\\
& (\tau-1)r &\text{if } r < 0\\
\end{array}
\end{equation}
\item Soft floor
\begin{equation}
l_2(r) = |r| + e^{-r}
\end{equation}
\end{enumerate}

Problem statement as absolutely monotonic, lowballing, noisy, (semi-)parametric. Discuss convexity. Discuss loss function (two versions, the one I end up using, and the one for convex optimization).
Summary of the rest of the document. State that we develop a method and compare it with others.

\section{Potential approaches}

Describe potential ways to solve the problem, both feasible and infeasible, introducing the theory behind them.

Exponential sums - Laplace transform, Bernstein theorem, relation between completely monotonic and absolutely monotonic functions.
Exponential sums - Absolutely monotonic functions in bounded domains are not always exponential sums.
Exponential sums - Prony methods.
Exponential sums - Least squares.
Exponential sums - other approaches.

Piecewise interpolation

Polynomial interpolation - Full representation of analytical functions.
Polynomial interpolation - Spectral methods infeasible.
Polynomial interpolation - Least squares using Vandermonde matrix.
Polynomial interpolation - Convex optimization of splines under loss.
Polynomial interpolation - Greedy lowballing monomial sum.

\section{Evaluation}

Discuss functions that are being tested, evaluation set up.

\section{Results and discussion}
Show different functions and discuss pros and cons.

\section{Conclusion}

\dobibliography

\end{document}